{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_w2v_fname = os.path.join('models_ok', 'ok-20161206.w2v.300.bin')\n",
    "model_w2v = Word2Vec.load(model_w2v_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9': 0, 'g': 1, '4': 20, 'ч': 3, 'и': 4, 'd': 6, 'M': 31, 'x': 9, 'z': 2, 'h': 13, 'c': 12, 'i': 46, 'm': 18, 'ж': 15, 'с': 17, 'ь': 19, 'j': 28, 'a': 21, 'r': 22, 's': 26, 'N': 25, 'b': 23, 'э': 66, '7': 7, 'u': 29, 'y': 30, 'f': 33, 'n': 32, 'ю': 41, 'п': 5, 'е': 34, 't': 54, 'а': 36, 'v': 37, 'o': 38, 'q': 40, 'к': 8, 'ы': 42, 'w': 35, 'ш': 24, 'в': 44, 'з': 45, 'д': 49, 'ъ': 27, 'м': 10, 'я': 47, 'о': 48, 'х': 50, '8': 51, 'й': 52, '#': 57, 'н': 53, 'б': 11, 'k': 55, 'ц': 56, 'U': 58, 'щ': 39, 'у': 59, '6': 60, 'e': 61, 'г': 62, 'ф': 63, 'т': 64, 'л': 14, 'p': 65, '3': 68, '1': 67, '0': 69, 'l': 16, '2': 43, '5': 70, 'р': 71}\n",
      "MAX_LEN =  20\n",
      "['проконсультироваться', 'сельскохозяйственных', 'благотворительностью', 'поэкспериментировать', 'среднестатистический', 'неприятностьнепогода', 'сельскохозяйственной']\n",
      "<built-in function len>\n"
     ]
    }
   ],
   "source": [
    "LEN_TRESHOLD = 20\n",
    "valid_id_word = [(i, model_w2v.index2word[i]) for i in range(len(model_w2v.index2word)) \n",
    "                  if len(model_w2v.index2word[i]) <= LEN_TRESHOLD]\n",
    "indexes, words = map(list, zip(*valid_id_word))\n",
    "vectors = model_w2v.syn0[np.array(indexes, dtype='int32')]\n",
    "vectors = vectors / np.linalg.norm(vectors, axis=1)[:, None]\n",
    "\n",
    "chars = list(set(''.join(words)))\n",
    "MAX_ID  = len(chars)\n",
    "MAX_LEN = max(len(s) for s in words)\n",
    "MAX_LEN = min(MAX_LEN, LEN_TRESHOLD)\n",
    "W2V_DIM = model_w2v.syn0.shape[1]\n",
    "\n",
    "\n",
    "char_to_id = { ch:id for id,ch in enumerate(chars) }\n",
    "id_to_char = { id:ch for id,ch in enumerate(chars) }\n",
    "print(char_to_id)\n",
    "print('MAX_LEN = ', MAX_LEN)\n",
    "print([s for s in model_w2v.index2word if len(s) == MAX_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_to_ohe_vector(word):\n",
    "    result = np.zeros([MAX_LEN, MAX_ID], dtype='int32')\n",
    "    for i in range(len(word)):\n",
    "        result[i, char_to_id[word[i]]] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 72)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ohe_vector('9dx').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Embedding, \\\n",
    "                         Convolution1D, GlobalMaxPooling1D, Lambda, Permute, merge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEN_B = 3\n",
    "LEN_E = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_b = Input(shape=(LEN_B, MAX_ID, ))\n",
    "input_m = Input(shape=(1, MAX_ID,  ))\n",
    "input_e = Input(shape=(LEN_E, MAX_ID, ))\n",
    "\n",
    "merged = merge([input_b, input_m, input_e], mode='concat', concat_axis=1)\n",
    "\n",
    "lstm_1 = LSTM(output_dim=128, return_sequences=True, input_dim=(LEN_E + LEN_B + 1, MAX_ID))(merged)\n",
    "lstm_2 = LSTM(100,return_sequences=True)(lstm_1)\n",
    "lstm_3 = LSTM(100)(lstm_2)\n",
    "\n",
    "dense_out = Dense(W2V_DIM)(lstm_3)\n",
    "\n",
    "mal_model = Model(input=[input_b, input_m, input_e], output=dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_46 (InputLayer)            (None, 3, 72)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_47 (InputLayer)            (None, 1, 72)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_48 (InputLayer)            (None, 3, 72)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 7, 72)         0           input_46[0][0]                   \n",
      "                                                                   input_47[0][0]                   \n",
      "                                                                   input_48[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                   (None, 7, 128)        102912      merge_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                   (None, 7, 100)        91600       lstm_21[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                   (None, 100)           80400       lstm_22[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 300)           30300       lstm_23[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 305212\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mal_model.summary()\n",
    "mal_model.compile(loss='cosine_proximity', optimizer='sgd', metrics=['cosine_proximity', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchGenerator(words, vectors, batch_size=20):\n",
    "    while 1:\n",
    "        X_b_batch = np.empty((0, LEN_B, MAX_ID))\n",
    "        X_e_batch = np.empty((0, LEN_E, MAX_ID))\n",
    "        X_m_batch = np.empty((0, 1, MAX_ID))\n",
    "        Y_batch   = np.empty((0, W2V_DIM))\n",
    "        \n",
    "        while Y_batch.shape[0] < batch_size:\n",
    "            i = np.random.choice(len(words))\n",
    "            len_w = len(words[i])\n",
    "            \n",
    "            word_ohe = word_to_ohe_vector(words[i])\n",
    "            X_b = word_ohe[:LEN_B]\n",
    "            \n",
    "            if len_w < LEN_E:\n",
    "                X_e = word_ohe[:LEN_E]\n",
    "            else:\n",
    "                X_e = word_ohe[len_w - LEN_E : len_w]\n",
    "            X_m = np.sum(word_ohe, axis=0)\n",
    "\n",
    "            Y = vectors[i]\n",
    "            yt = model_w2v[words[i]] \n",
    "            yt = yt / np.linalg.norm(yt)\n",
    "            assert np.allclose(Y, yt)\n",
    "            X_b_batch = np.concatenate((X_b_batch, X_b[None, ...]))\n",
    "            X_e_batch = np.concatenate((X_e_batch, X_e[None, ...]))\n",
    "            X_m_batch = np.concatenate((X_m_batch, X_m[None, None, ...]))\n",
    "            Y_batch   = np.concatenate((Y_batch, Y[None, ...]))\n",
    "            \n",
    "        yield [X_b_batch, X_m_batch, X_e_batch], Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3, 72)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, y in batchGenerator(words, vectors):\n",
    "    print(x[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 32s - loss: -1.3475e-05 - cosine_proximity: -1.3475e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 31s - loss: -2.5621e-05 - cosine_proximity: -2.5621e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 32s - loss: -3.9383e-05 - cosine_proximity: -3.9383e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 27s - loss: -5.3007e-05 - cosine_proximity: -5.3007e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 32s - loss: -6.4360e-05 - cosine_proximity: -6.4360e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 28s - loss: -8.0318e-05 - cosine_proximity: -8.0318e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 27s - loss: -9.2908e-05 - cosine_proximity: -9.2908e-05 - mean_squared_error: 0.0039    \n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 28s - loss: -1.0051e-04 - cosine_proximity: -1.0051e-04 - mean_squared_error: 0.0039    \n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 32s - loss: -1.1457e-04 - cosine_proximity: -1.1457e-04 - mean_squared_error: 0.0039    \n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 28s - loss: -1.2891e-04 - cosine_proximity: -1.2891e-04 - mean_squared_error: 0.0038    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76970775f8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_model.fit_generator(batchGenerator(words, vectors), samples_per_epoch=6000, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(model_w2v, model, word='апельсин'):\n",
    "    len_w = len(word)\n",
    "    word_ohe = word_to_ohe_vector(word)\n",
    "    X_b = word_ohe[:LEN_B]\n",
    "\n",
    "    if len_w < LEN_E:\n",
    "                    X_e = word_ohe[:LEN_E]\n",
    "    else:\n",
    "                    X_e = word_ohe[len_w - LEN_E : len_w]\n",
    "    X_m = np.sum(word_ohe, axis=0)\n",
    "    \n",
    "    res = model.predict([X_b.reshape(1, *X_b.shape), \n",
    "                         X_m.reshape(1, 1, *X_m.shape), \n",
    "                         X_e.reshape(1, *X_e.shape)])\n",
    "    \n",
    "    \n",
    "    print('cosine similarity:', \n",
    "          1 - scipy.spatial.distance.cosine(model_w2v[word], res[0]))\n",
    "    \n",
    "    print('sim-by-vec:')\n",
    "    print(model_w2v.similar_by_vector(res[0]))\n",
    "    print('sim original:')\n",
    "    print(model_w2v.most_similar(word))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity: 0.216107856305\n",
      "sim-by-vec:\n",
      "[('небывалое', 0.27472907304763794), ('плазма', 0.27139419317245483), ('дальнее', 0.2707824110984802), ('швейцарском', 0.26794761419296265), ('кале', 0.26429155468940735), ('мане', 0.26239538192749023), ('владивосток', 0.2604215741157532), ('выстраиваются', 0.2596675753593445), ('оро', 0.25935834646224976), ('титан', 0.25295913219451904)]\n",
      "sim original:\n",
      "[('электрички', 0.5722105503082275), ('рельс', 0.5523016452789307), ('тротуару', 0.532254695892334), ('машинист', 0.5239666700363159), ('трамваи', 0.5168241262435913), ('вагону', 0.5130778551101685), ('вагоны', 0.5127475261688232), ('галопом', 0.5120807886123657), ('резво', 0.5074643492698669), ('ползут', 0.5065412521362305)]\n"
     ]
    }
   ],
   "source": [
    "v = test(model_w2v, mal_model, 'рельсам')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
